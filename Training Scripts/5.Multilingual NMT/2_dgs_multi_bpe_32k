#!/bin/bash
pip install sacrebleu
echo "export LC_ALL=C">>~/.bashrc
source ~/.bashrc

MODELNAME=dgs_baseline_transformer_lemmnorm_multilingual_bpe_32k
PWD=/netscratch/zhu/submission
SEC=$PWD/section5
TRAINTEXT=$PWD/data/t2g_dgs/train/dgs_sentences_train_lower_lemm.txt
TRAINGLOSS=$PWD/data/t2g_dgs/train/dgs_glosses_train_lower_all_cleaned.txt
DEVTEXT=$PWD/data/t2g_dgs/dev/dgs_sentences_dev_lower_lemm.txt
DEVGLOSS=$PWD/data/t2g_dgs/dev/dgs_glosses_dev_lower_all_cleaned.txt
TESTTEXT=$PWD/data/t2g_dgs/test/dgs_sentences_test_lower_lemm.txt
TESTGLOSS=$PWD/data/t2g_dgs/test/dgs_glosses_test_lower_all_cleaned.txt
mosesdecoder=$PWD/mosesdecoder
subword_nmt=$PWD/subword-nmt/subword_nmt
SRC=de
TRG=en
bpe_operations=32000
mkdir -p $SEC/model/$MODELNAME
mkdir -p $SEC/model/$MODELNAME/output
path=$SEC/model/$MODELNAME
#wget https://data.statmt.org/news-commentary/v16/training/news-commentary-v16.de-en.tsv.gz
#gzip -d news-commentary-v16.de-en.tsv.gz

cat $SEC/news-commentary-v16.de-en.tsv | awk -F'\t' '{print $1}' > $path/news-commentary-v16.$SRC
cat $SEC/news-commentary-v16.de-en.tsv | awk -F'\t' '{print $2}' > $path/news-commentary-v16.$TRG

cat $SEC/model/$MODELNAME/news-commentary-v16.$SRC \
        | $mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -l $SRC \
        | $mosesdecoder/scripts/tokenizer/tokenizer.perl -a -l $SRC > $SEC/model/$MODELNAME/news-commentary-v16.tok.$SRC
test -f $SEC/model/$MODELNAME/news-commentary-v16.$TRG || continue
cat $SEC/model/$MODELNAME/news-commentary-v16.$TRG \
        | $mosesdecoder/scripts/tokenizer/normalize-punctuation.perl -l $TRG \
        | $mosesdecoder/scripts/tokenizer/tokenizer.perl -a -l $TRG > $SEC/model/$MODELNAME/news-commentary-v16.tok.$TRG
mv $SEC/model/$MODELNAME/news-commentary-v16.tok.$SRC $SEC/model/$MODELNAME/news-commentary-v16.tok.uncleaned.$SRC
mv $SEC/model/$MODELNAME/news-commentary-v16.tok.$TRG $SEC/model/$MODELNAME/news-commentary-v16.tok.uncleaned.$TRG
$mosesdecoder/scripts/training/clean-corpus-n.perl $SEC/model/$MODELNAME/news-commentary-v16.tok.uncleaned $SRC $TRG $SEC/model/$MODELNAME/news-commentary-v16.tok 1 100

$mosesdecoder/scripts/recaser/train-truecaser.perl -corpus $SEC/model/$MODELNAME/news-commentary-v16.tok.$SRC -model $path/tc.$SRC
$mosesdecoder/scripts/recaser/train-truecaser.perl -corpus $SEC/model/$MODELNAME/news-commentary-v16.tok.$TRG -model $path/tc.$TRG
$mosesdecoder/scripts/recaser/truecase.perl -model $path/tc.$SRC < $SEC/model/$MODELNAME/news-commentary-v16.tok.$SRC > $SEC/model/$MODELNAME/news-commentary-v16.tc.$SRC
test -f $SEC/model/$MODELNAME/news-commentary-v16.tok.$TRG || continue
$mosesdecoder/scripts/recaser/truecase.perl -model $path/tc.$TRG < $SEC/model/$MODELNAME/news-commentary-v16.tok.$TRG > $SEC/model/$MODELNAME/news-commentary-v16.tc.$TRG
mkdir -p $SEC/model/$MODELNAME/tagged
tagged=$SEC/model/$MODELNAME/tagged
cat $SEC/model/$MODELNAME/news-commentary-v16.tc.$SRC | sed 's/^/<2en> /' $SEC/model/$MODELNAME/news-commentary-v16.tc.$SRC > $SEC/model/$MODELNAME/news-commentary-v16.tc.tag.$SRC
cat $TRAINTEXT | sed 's/^/<2gloss> /' $TRAINTEXT > $tagged/traintext.txt
cat $DEVTEXT | sed 's/^/<2gloss> /' $DEVTEXT > $tagged/devtext.txt
cat $TESTTEXT | sed 's/^/<2gloss> /' $TESTTEXT > $tagged/testtext.txt

left=$SEC/model/$MODELNAME/news-commentary-v16.tc.tag.$SRC
right=$SEC/model/$MODELNAME/news-commentary-v16.tc.$TRG

cat $left $tagged/traintext.txt > $SEC/model/$MODELNAME/newtext.txt
cat $right $TRAINGLOSS > $SEC/model/$MODELNAME/newgloss.txt

NEWTEXT=$SEC/model/$MODELNAME/newtext.txt
NEWGLOSS=$SEC/model/$MODELNAME/newgloss.txt
cat $NEWTEXT $NEWGLOSS | $subword_nmt/learn_bpe.py -s $bpe_operations > $path/$SRC$TRG.bpe

$subword_nmt/apply_bpe.py -c $path/$SRC$TRG.bpe < $NEWTEXT > $path/corpus.bpe.$SRC
test -f $NEWGLOSS || continue
$subword_nmt/apply_bpe.py -c $path/$SRC$TRG.bpe < $NEWGLOSS > $path/corpus.bpe.$TRG

$subword_nmt/apply_bpe.py -c $path/$SRC$TRG.bpe < $tagged/devtext.txt > $path/dev.bpe.$SRC
test -f $DEVGLOSS || continue
$subword_nmt/apply_bpe.py -c $path/$SRC$TRG.bpe < $DEVGLOSS > $path/dev.bpe.$TRG

$subword_nmt/apply_bpe.py -c $path/$SRC$TRG.bpe < $tagged/testtext.txt > $path/test.bpe.$SRC
test -f $TESTGLOSS || continue
$subword_nmt/apply_bpe.py -c $path/$SRC$TRG.bpe < $TESTGLOSS > $path/test.bpe.$TRG

cat $path/corpus.bpe.de $path/corpus.bpe.en | /marian/build/marian-vocab --max-size 32000 > $path/vocab.deen.yml
        /marian/build/marian \
        --devices 0 1 \
        --model $path/$MODELNAME.npz \
        --type transformer \
        --layer-normalization \
        --mini-batch-fit -w 10000 --maxi-batch 1000 \
        --quiet-translation \
        --learn-rate 0.0003 --lr-warmup 16000 \
        --lr-decay-inv-sqrt 16000 --lr-report \
        --optimizer adam \
        --early-stopping 5 \
        --cost-type=ce-mean-words \
        --valid-metrics perplexity bleu-detok ce-mean-words translation chrf bleu \
        --train-sets $path/corpus.bpe.de $path/corpus.bpe.en \
        --vocabs $path/vocab.deen.yml $path/vocab.deen.yml \
        --valid-sets $path/dev.bpe.de $path/dev.bpe.en \
        --log $path/train.log \
        --valid-log $path/valid.log --valid-mini-batch 64 \
        --valid-script-path $SEC/valid_dgs.sh \
        --valid-translation-output $path/output/dev_output_pre.txt \
        --keep-best \
        --valid-freq 2500 \
        --disp-freq 2500 \
        --dim-emb 512 --transformer-dim-ffn 2048 --transformer-heads 8 --transformer-ffn-activation relu --enc-depth 6 --dec-depth 6 --enc-cell lstm \
        --enc-cell-depth 2 --dec-cell-base-depth 2 --dec-cell lstm \
        --sync-sgd --dropout-src 0.1 --dropout-trg 0.1 \
        --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --beam-size 6 --normalize 0.6 \
        --exponential-smoothing --seed 1111 \
        --tied-embeddings-all \
        --transformer-dropout 0.2 --label-smoothing 0.1 \


cat $path/dev.bpe.de | /marian/build/marian-decoder -c $path/$MODELNAME.npz.best-bleu-detok.npz.decoder.yml -d 0 1 -b 6 -n 0.6 \
	 --mini-batch 64 --maxi-batch 100 --maxi-batch-sort src \
	 | sed 's/\@\@ //g' \
	 | $mosesdecoder/scripts/tokenizer/detokenizer.perl -l de \
	 > $path/output/dev_output.txt

cat $path/test.bpe.de | /marian/build/marian-decoder -c $path/$MODELNAME.npz.best-bleu-detok.npz.decoder.yml -d 0 1 -b 6 -n 0.6 \
	--mini-batch 64 --maxi-batch 100 --maxi-batch-sort src \
	| sed 's/\@\@ //g' \
	| $mosesdecoder/scripts/tokenizer/detokenizer.perl -l de \
	> $path/output/test_output.txt
echo "------------------BLEU SCORE OF DEV--------------------"
$PWD/sacrebleu/sacrebleu/sacrebleu.py $DEVGLOSS -i $SEC/model/$MODELNAME/output/dev_output.txt -m bleu chrf ter -b -w 4 -tok none
echo "------------------BLEU SCORE OF TEST-------------------"
$PWD/sacrebleu/sacrebleu/sacrebleu.py $TESTGLOSS -i $SEC/model/$MODELNAME/output/test_output.txt -m bleu chrf ter -b -w 4 -tok none


